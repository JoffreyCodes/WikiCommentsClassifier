{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Talk Data - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an introduction to working with the various data sets in [Wikipedia\n",
    "Talk](https://figshare.com/projects/Wikipedia_Talk/16731) project on Figshare. The release includes:\n",
    "\n",
    "1. a large historical corpus of discussion comments on Wikipedia talk pages\n",
    "2. a sample of over 100k comments with human labels for whether the comment contains a personal attack\n",
    "3. a sample of over 100k comments with human labels for whether the comment has aggressive tone\n",
    "\n",
    "Please refer to our [wiki](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release) for documentation of the schema of each data set and our [research paper](https://arxiv.org/abs/1610.08914) for documentation on the data collection and modeling methodology. \n",
    "\n",
    "In this notebook we show how to build a simple classifier for detecting personal attacks and apply the classifier to a random sample of the comment corpus to see whether discussions on user pages have more personal attacks than discussion on article pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classifier for personal attacks\n",
    "In this section we will train a simple bag-of-words classifier for personal attacks using the [Wikipedia Talk Labels: Personal Attacks]() data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# You can edit the code here to download only once, and not download it later                \n",
    "download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annotators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'year', 'logged_in', 'ns', 'sample', 'split', 'attack'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21b655ef790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize\n",
    "plt.scatter(comments['year'], comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['attack'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove comments with no recorded attacks\n",
    "comments = comments.query(\"year>=2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554005</th>\n",
       "      <td>The references to the Congolese economy se...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569192</th>\n",
       "      <td>`   I cut the following paragraph, which misle...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583986</th>\n",
       "      <td>Dear Mav: Thanks, bro! God bless you!  Since...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593977</th>\n",
       "      <td>`  That's true. I removed similar passages, wh...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600918</th>\n",
       "      <td>`  :Yes, thanks! I have implemented something ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622095</th>\n",
       "      <td>`This page is ridiculous.  The author throws i...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633526</th>\n",
       "      <td>```2000's: The Jewish blood-libel myth continu...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509</th>\n",
       "      <td>MarcusAurelius]]   Why exactly was this user b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680470</th>\n",
       "      <td>There is no such thing as Christian religiocen...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694840</th>\n",
       "      <td>`  :Click on my ``Annoying Users`` link! I gue...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "554005      The references to the Congolese economy se...  2003       True   \n",
       "569192  `   I cut the following paragraph, which misle...  2003       True   \n",
       "583986    Dear Mav: Thanks, bro! God bless you!  Since...  2003       True   \n",
       "593977  `  That's true. I removed similar passages, wh...  2003       True   \n",
       "600918  `  :Yes, thanks! I have implemented something ...  2003       True   \n",
       "622095  `This page is ridiculous.  The author throws i...  2003       True   \n",
       "633526  ```2000's: The Jewish blood-libel myth continu...  2003       True   \n",
       "661509  MarcusAurelius]]   Why exactly was this user b...  2003      False   \n",
       "680470  There is no such thing as Christian religiocen...  2003       True   \n",
       "694840  `  :Click on my ``Annoying Users`` link! I gue...  2003       True   \n",
       "\n",
       "             ns   sample  split  attack  \n",
       "rev_id                                   \n",
       "554005     user   random  train   False  \n",
       "569192  article   random  train   False  \n",
       "583986     user   random  train   False  \n",
       "593977  article   random   test   False  \n",
       "600918     user   random  train   False  \n",
       "622095  article   random   test   False  \n",
       "633526  article   random  train   False  \n",
       "661509     user  blocked  train   False  \n",
       "680470  article   random  train   False  \n",
       "694840     user   random  train   False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check removal\n",
    "comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional text cleanup (lowercase, punctuations, numbers)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.lower())\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), \" \", x))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: re.sub('\\w*\\d\\w*', \" \", x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554005</th>\n",
       "      <td>the references to the congolese economy se...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569192</th>\n",
       "      <td>i cut the following paragraph  which misle...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583986</th>\n",
       "      <td>dear mav  thanks  bro  god bless you   since...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593977</th>\n",
       "      <td>that s true  i removed similar passages  wh...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600918</th>\n",
       "      <td>yes  thanks  i have implemented something ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622095</th>\n",
       "      <td>this page is ridiculous   the author throws i...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633526</th>\n",
       "      <td>s  the jewish blood libel myth continues ...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509</th>\n",
       "      <td>marcusaurelius     why exactly was this user b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680470</th>\n",
       "      <td>there is no such thing as christian religiocen...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694840</th>\n",
       "      <td>click on my   annoying users   link  i gue...</td>\n",
       "      <td>2003</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "554005      the references to the congolese economy se...  2003       True   \n",
       "569192      i cut the following paragraph  which misle...  2003       True   \n",
       "583986    dear mav  thanks  bro  god bless you   since...  2003       True   \n",
       "593977     that s true  i removed similar passages  wh...  2003       True   \n",
       "600918      yes  thanks  i have implemented something ...  2003       True   \n",
       "622095   this page is ridiculous   the author throws i...  2003       True   \n",
       "633526       s  the jewish blood libel myth continues ...  2003       True   \n",
       "661509  marcusaurelius     why exactly was this user b...  2003      False   \n",
       "680470  there is no such thing as christian religiocen...  2003       True   \n",
       "694840      click on my   annoying users   link  i gue...  2003       True   \n",
       "\n",
       "             ns   sample  split  attack  \n",
       "rev_id                                   \n",
       "554005     user   random  train   False  \n",
       "569192  article   random  train   False  \n",
       "583986     user   random  train   False  \n",
       "593977  article   random   test   False  \n",
       "600918     user   random  train   False  \n",
       "622095  article   random   test   False  \n",
       "633526  article   random  train   False  \n",
       "661509     user  blocked  train   False  \n",
       "680470  article   random  train   False  \n",
       "694840     user   random  train   False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cleanup\n",
    "comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279             iraq is not good            usa is bad   \n",
       "2702703           fuck off you little asshole  if you wan...\n",
       "4632658         i have a dick  its bigger than yours  hahaha\n",
       "6545332         renault     you sad little bpy for drivin...\n",
       "6545351         renault     you sad little bo for driving...\n",
       "7977970         nov    utc     because you like to accuse...\n",
       "8359431         you are not worth the effort  you are arg...\n",
       "8724028    yes  complain to your rabbi and then go shoot ...\n",
       "8845700                     i am using the sandbox  ass wipe\n",
       "8845736         god damn     god damn it fuckers  i am us...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cleanup on attack comments\n",
    "comments.query('attack')['comment'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Cross-validation (test = .3, train = .7 (complimentary))\n",
    "train_comments, test_comments = train_test_split(comments, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "# fit a simple text classifier\n",
    "\n",
    "estimators = [    \n",
    "    ('vect', TfidfVectorizer(max_features = 10000, \n",
    "                             analyzer = 'word', \n",
    "                             ngram_range = (1,2), \n",
    "                             stop_words='english'\n",
    "                            )),\n",
    "    ('clf', LinearSVC(penalty='l2',\n",
    "                      loss='squared_hinge', \n",
    "                      dual=False, \n",
    "                      tol=0.0001, \n",
    "                      C=1.0, \n",
    "                      multi_class='ovr', \n",
    "                      fit_intercept=True, \n",
    "                      intercept_scaling=1, \n",
    "                      class_weight=None, \n",
    "                      verbose=0, \n",
    "                      random_state=5, \n",
    "                      max_iter=10000\n",
    "                     ))\n",
    "]\n",
    "\n",
    "clf = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     30722\n",
      "        True       0.85      0.64      0.73      4021\n",
      "\n",
      "    accuracy                           0.95     34743\n",
      "   macro avg       0.90      0.81      0.85     34743\n",
      "weighted avg       0.94      0.95      0.94     34743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95480066, 0.14840408],\n",
       "       [0.04519934, 0.85159592]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# add confusion matrix\n",
    "confusion_matrix(test_comments['attack'], clf.predict(test_comments['comment']), normalize = 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['i like you'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "a. What text cleaning methods did you try? Which are the ones you included in the final code?\n",
    "    - Filter out stop words via TfidfVectorizer(stop_words='english')\n",
    "\t- Lowercase all text\n",
    "    - Remove numbers\n",
    "    - Remove punctuations\n",
    "    \n",
    "b. What are the features you considered using? Which features did you use in the final code?\n",
    "    - Tried Unigrams, Bigrams, Both; analyzing words\n",
    "\t- chars with ngram 1-5 but memory filled up; author suggested this was the best approach but I was not able to reproduce results.\n",
    "    - Stop words via TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "c. How did you decide to use the ‘attack’ information from different annotators? Did you average them, or use a number threshold, or did you use some other method to use this information?\n",
    "    - Manipulating the labels mean() to be less than majority or greater than majority effected the f1 scores such that further deviation away from labels mean() > 0.5 resulted in decreasing the f1-score for correctly classifying nasty comments. However, increasing the threshold improves the f1-score for correctly classifying nice comments as \"false\" and ultimately improved thed weighted average f1 score. Therefore, I felt it more appropriate to maximize the correct classification for nast comments as this is more of the general purpose for this classifier.     \n",
    "    \n",
    "d. What optimizations did you add in your code, if any?\n",
    "\t- Removed comments before 2003, there were no recorded attacks; approximately 8 comments, did not significantly affect results whatsoever\n",
    "    - Use of stopwords\n",
    "\n",
    "e. What are the ML methods you tried out, and what were your best results with each method? Which was the best ML method you saw before tuning hyperparameters?\n",
    "    - LogisticRegression (Second best)\n",
    "    - MultinomialNB (Naieve Bayes)\n",
    "    - LinearSVC(Best results)\n",
    "    Tuning hyperparameters for LinearSVC did not significantly improve my results.\n",
    "    \n",
    "f. What hyper-parameter tuning did you do, and by how many percentage points did your accuracy go up because of hyper-parameter tuning?\n",
    "     - A slight increase of 1% is seen in our True precision, but this could be from a randomized state computation of our data. Accuracy did not change from 0.94 overall.\n",
    "\n",
    "g. What did you learn from the different metrics? Did you try cross-validation?\n",
    "    - From the metrics, it seems that our data strongly supports classifying nice comments. This makes sense since supporting comments(30k) are about 7x more evident than nasty comments(4k) in our processed and pipelined dataset. I was unable to try cross-validation, but I did try to implement a train_test_split using test = 0.3 and complimentary train = 0.7. The accuracy started at 0.91\n",
    "\n",
    "h. What are your best final Result Metrics? What is the increase in accuracy compared to the strawman figure? Which model gave you this performance?\n",
    "    - My best final result metric was getting the True f1-score above 0.7 which started from the strawman True f1-score of 0.63. This was acchieved using LinearSVC with default parameters\n",
    "    \n",
    "i. What is the most interesting thing you learned from doing the report?\n",
    "    -I really enjoyed working in jupyter. It's particularly interesting how reports in jupyter literally feels like reading a journal entry or report, rather than code structures formatted in an IDE. \n",
    "\n",
    "j. What was the hardest thing to do?\n",
    "    - Reading all the documentation for sklearn libraries. Theres so much to learn and improve!\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
